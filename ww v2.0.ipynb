{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram model using a Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27, 27), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training set of biagrams (x, y)\n",
    "xs , ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "        # N[ix1, ix2] += 1\n",
    "\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "yenc = F.one_hot(ys, num_classes=27).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29e64be4a70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6032,  1.0180, -0.4837, -1.8007, -1.8144, -0.8499, -1.9622,  0.4473,\n",
       "          0.4798,  0.4807, -0.3117,  0.6734, -0.5502,  0.9846,  0.6919, -0.2947,\n",
       "          1.2276,  0.7094, -1.0339,  0.7753,  0.4209,  0.5758, -0.1756, -0.1250,\n",
       "         -0.5255,  0.6801, -1.2057],\n",
       "        [ 0.0720, -0.2319, -1.3363, -0.6863, -0.9899,  0.7867,  0.4492, -0.0146,\n",
       "         -0.9969,  0.3031, -1.1894,  0.9084, -1.5123, -0.6809,  0.0475, -0.1839,\n",
       "          0.0379, -0.3809, -1.5802, -0.4651, -1.2537,  0.1175,  1.3636, -0.4044,\n",
       "          0.9003, -0.6352,  1.6250],\n",
       "        [ 1.2743, -1.0605, -0.2277, -0.4241, -1.9743, -1.1278,  0.4209,  1.5459,\n",
       "          1.1946,  0.1228, -0.2045,  1.7500,  0.3768, -0.3090, -0.2224,  0.6410,\n",
       "          0.4660, -1.3774,  0.0788, -2.0866,  0.9380, -0.3246, -2.2365, -0.4174,\n",
       "         -1.0568,  0.0905, -1.0935],\n",
       "        [ 1.2743, -1.0605, -0.2277, -0.4241, -1.9743, -1.1278,  0.4209,  1.5459,\n",
       "          1.1946,  0.1228, -0.2045,  1.7500,  0.3768, -0.3090, -0.2224,  0.6410,\n",
       "          0.4660, -1.3774,  0.0788, -2.0866,  0.9380, -0.3246, -2.2365, -0.4174,\n",
       "         -1.0568,  0.0905, -1.0935],\n",
       "        [ 0.1609, -0.3969, -0.0055, -0.1356, -0.7743, -1.3535, -1.9445,  0.9789,\n",
       "         -1.4836, -1.5735, -0.0520,  0.7894,  0.4601, -0.2954,  0.5912, -0.4844,\n",
       "         -1.4851,  1.2015, -0.9196,  0.5097,  0.5417,  0.5531,  1.1327, -0.1914,\n",
       "         -0.0176, -1.6928, -0.0478]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.randn((27,27))\n",
    "(xenc @ w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = (xenc @ w) #log-counts\n",
    "counts = logits.exp() #equivalent N\n",
    "probs = counts / counts.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes the weights of 27 neurons randomly, each receives 27 inputs\n",
    "# 27 inputs -> 27 neurons\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "\n",
    "# Forward (passing) propagation\n",
    "logits = xenc @ w\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "# Last 2 lines are together Softmax (activation function)\n",
    "# It takes input (an output layer of floats) and convert them to probabilities\n",
    "# can be applied to any NN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "biagram exampple 1: .e (indexes 0, 5)\n",
      "log likelihood:  -4.371180534362793\n",
      "Negative log likelihood:  4.371180534362793\n",
      "---------------\n",
      "biagram exampple 2: em (indexes 5, 13)\n",
      "log likelihood:  -4.130298614501953\n",
      "Negative log likelihood:  4.130298614501953\n",
      "---------------\n",
      "biagram exampple 3: mm (indexes 13, 13)\n",
      "log likelihood:  -3.9149699211120605\n",
      "Negative log likelihood:  3.9149699211120605\n",
      "---------------\n",
      "biagram exampple 4: ma (indexes 13, 1)\n",
      "log likelihood:  -4.666500568389893\n",
      "Negative log likelihood:  4.666500568389893\n",
      "---------------\n",
      "biagram exampple 5: a. (indexes 1, 0)\n",
      "log likelihood:  -3.263277769088745\n",
      "Negative log likelihood:  3.263277769088745\n",
      "=========\n",
      "Avg negative log likelihood, i.e. loss =  4.069245338439941\n"
     ]
    }
   ],
   "source": [
    "nlls = torch.zeros(5)\n",
    "\n",
    "for i in range(5):\n",
    "    x = xs[i].item()\n",
    "    y = ys[i].item()\n",
    "    \n",
    "    print('---------------')\n",
    "    print(f'biagram exampple {i+1}: {itos[x]}{itos[y]} (indexes {x}, {y})')\n",
    "    p = probs[i, y]\n",
    "    logp = torch.log(p)\n",
    "    print('log likelihood: ', logp.item())\n",
    "\n",
    "    nll = -logp\n",
    "    print('Negative log likelihood: ', nll.item())\n",
    "    nlls[i] = nll\n",
    "\n",
    "print('=========') \n",
    "print('Avg negative log likelihood, i.e. loss = ', nlls.mean().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Pass\n",
    "logits = (xenc @ W) #log-counts\n",
    "counts = logits.exp() #equivalent N\n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "loss = -probs[torch.arange(5), ys].log().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass\n",
    "W.grad = None\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.data += -0.1 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7693049907684326\n"
     ]
    }
   ],
   "source": [
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7492, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = (xenc @ W) #log-counts\n",
    "counts = logits.exp() #equivalent N\n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "loss = -probs[torch.arange(5), ys].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# Create the data set\n",
    "xs , ys = [], []\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "        # N[ix1, ix2] += 1\n",
    "\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('Number of examples: ', num)\n",
    "\n",
    "# Initialize the network\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9665, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regularization Term\n",
    "(W**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.72546911239624\n",
      "4.2028303146362305\n",
      "3.8577470779418945\n",
      "3.6194915771484375\n",
      "3.449573040008545\n",
      "3.3243706226348877\n",
      "3.230109691619873\n",
      "3.158154010772705\n",
      "3.1026480197906494\n",
      "3.059464693069458\n",
      "3.0256333351135254\n",
      "2.998974084854126\n",
      "2.977867364883423\n",
      "2.961090087890625\n",
      "2.947709083557129\n",
      "2.9370062351226807\n",
      "2.9284229278564453\n",
      "2.9215238094329834\n",
      "2.9159674644470215\n",
      "2.9114837646484375\n",
      "2.9078590869903564\n",
      "2.904924154281616\n",
      "2.9025444984436035\n",
      "2.9006123542785645\n",
      "2.899041175842285\n",
      "2.8977625370025635\n",
      "2.8967204093933105\n",
      "2.895869493484497\n",
      "2.8951754570007324\n",
      "2.8946077823638916\n",
      "2.8941433429718018\n",
      "2.8937625885009766\n",
      "2.8934507369995117\n",
      "2.893195152282715\n",
      "2.8929853439331055\n",
      "2.892812490463257\n",
      "2.8926708698272705\n",
      "2.89255428314209\n",
      "2.892458200454712\n",
      "2.89237904548645\n",
      "2.8923139572143555\n",
      "2.892260789871216\n",
      "2.892216205596924\n",
      "2.892179489135742\n",
      "2.8921492099761963\n",
      "2.8921241760253906\n",
      "2.892103672027588\n",
      "2.8920867443084717\n",
      "2.8920724391937256\n",
      "2.8920607566833496\n",
      "2.8920512199401855\n",
      "2.892042875289917\n",
      "2.8920364379882812\n",
      "2.892030954360962\n",
      "2.892026424407959\n",
      "2.8920228481292725\n",
      "2.892019748687744\n",
      "2.892016649246216\n",
      "2.892014741897583\n",
      "2.8920130729675293\n",
      "2.8920114040374756\n",
      "2.89201021194458\n",
      "2.8920090198516846\n",
      "2.8920083045959473\n",
      "2.892007827758789\n",
      "2.892007350921631\n",
      "2.8920063972473145\n",
      "2.8920063972473145\n",
      "2.8920059204101562\n",
      "2.892005443572998\n",
      "2.892005205154419\n",
      "2.89200496673584\n",
      "2.89200496673584\n",
      "2.8920044898986816\n",
      "2.8920047283172607\n",
      "2.8920042514801025\n",
      "2.8920042514801025\n",
      "2.8920044898986816\n",
      "2.8920042514801025\n",
      "2.8920042514801025\n",
      "2.8920042514801025\n",
      "2.8920044898986816\n",
      "2.8920040130615234\n",
      "2.8920042514801025\n",
      "2.8920042514801025\n",
      "2.8920042514801025\n",
      "2.8920042514801025\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920044898986816\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920040130615234\n",
      "2.8920042514801025\n",
      "2.8920044898986816\n",
      "2.8920042514801025\n",
      "2.8920040130615234\n",
      "2.8920042514801025\n",
      "2.8920037746429443\n",
      "2.8920040130615234\n"
     ]
    }
   ],
   "source": [
    "# Gradient Descent\n",
    "\n",
    "for k in range(100):\n",
    "    # Forward \n",
    "    xenc = F.one_hot(xs, num_classes=27).float()\n",
    "    logits = (xenc @ W) #log-counts\n",
    "    counts = logits.exp() #equivalent N\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    loss = -probs[torch.arange(num), ys].log().mean() + 1*(W**2).mean()\n",
    "    print(loss.item())\n",
    "\n",
    "    # Backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the data\n",
    "    W.data += -30 * W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juwjdedianaqah.\n",
      "p.\n",
      "cfaywe.\n",
      "nn.\n",
      "kshin.\n",
      "toleras.\n",
      "gwzzusahnaauyanileviackdbdainrwietlesnjyievylartezffvmumthyfontumj.\n",
      "pfynszwjh.\n",
      "janq.\n",
      "core.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "\n",
    "        # p = P[ix]\n",
    "\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "        logits = xenc @ W                           # predict log-counts\n",
    "        counts = logits.exp()                       # counts, equivalent to N (count Matrix)\n",
    "        p = counts / counts.sum(1, keepdim=True)    # probabilities for the next character\n",
    "\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "                \n",
    "        if ix == 0:\n",
    "            break\n",
    "\n",
    "    print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
